# ============================================
# Spark Application Configuration
# ============================================

# -----------------------------
# Application Settings
# -----------------------------
spark.app.name                     Balogo_Raphael_Spark_Playground
# Options could be local[*], yarn, mesos, or spark://<host>:<port>.
spark.master                       spark://localhost:7077

# -----------------------------
# Driver Settings
# -----------------------------
spark.driver.memory                2g
spark.driver.extraJavaOptions      -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps  -Xloggc:/mnt/c/wsl_mount_point/spark_logs/driver_logs/driver.stdout.gc.log

# -----------------------------
# Executor Settings
# -----------------------------
spark.decommission.enabled         true
spark.executor.instances           5
spark.executor.memory              2g
spark.executor.cores               1
spark.executor.decommission.forceKillTimeout    120s

# -----------------------------
# Executor Log Rolling Settings
# -----------------------------
# Roll executor logs when the file size exceeds 100MB.
spark.executor.logs.rolling.strategy        time-size
spark.executor.logs.rolling.maxSize         100m
# Number of rolled log files to keep per executor.
spark.executor.logs.rolling.maxRetainedFiles  5
# Limit total size of all retained rolled log files (Spark 3.4+).
spark.executor.logs.rolling.maxRetainedFileSize  512m
# Enable compression of old rolled log files to save disk space.
spark.executor.logs.rolling.enableCompression   true


# -----------------------------
# SQL Settings
# -----------------------------
spark.sql.shuffle.partitions       100
spark.sql.adaptive.autoBroadcastJoinThreshold 250m
spark.sql.adaptive.forceOptimizeSkewedJoin true
spark.shuffle.accurateBlockSkewedFactor 3
spark.sql.adaptive.skewJoin.skewedPartitionFactor 3
spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes 100mb
spark.sql.adaptive.shuffle.targetPostShuffleInputSize 64m
spark.sql.cbo.enabled true
spark.sql.cbo.joinReorder.enabled true
spark.sql.execution.arrow.pyspark.enabled true
spark.sql.execution.pythonUDF.arrow.enabled true
spark.sql.hive.convertMetastoreParquet.mergeSchema true
spark.sql.planner.pythonExecution.memory 6g
spark.sql.pyspark.inferNestedDictAsStruct.enabled true
spark.sql.pyspark.udf.profiler true
spark.sql.repl.eagerEval.enabled true
spark.sql.shuffleDependency.fileCleanup.enabled true
spark.sql.shuffleDependency.skipMigration.enabled true
spark.sql.sources.v2.bucketing.enabled true
spark.sql.sources.v2.bucketing.allowCompatibleTransforms.enabled true
spark.sql.sources.v2.bucketing.allowJoinKeysSubsetOfPartitionKeys.enabled true
spark.sql.sources.v2.bucketing.partiallyClusteredDistribution.enabled true
spark.sql.sources.v2.bucketing.partition.filter.enabled true
spark.sql.sources.v2.bucketing.shuffle.enabled true
spark.sql.sources.v2.bucketing.sorting.enabled true
spark.sql.statistics.size.autoUpdate.enabled true
spark.sql.statistics.fallBackToHdfs true
spark.sql.statistics.updatePartitionStatsInAnalyzeTable.enabled true
spark.sql.streaming.metricsEnabled true
spark.sql.streaming.forceDeleteTempCheckpointLocation true
spark.sql.streaming.stopTimeout 120000
spark.sql.thriftServer.queryTimeout 240000
spark.sql.thriftServer.interruptOnCancel true
spark.sql.hive.thriftServer.singleSession true
spark.streaming.stopGracefullyOnShutdown true
# spark.sql.streaming.sessionWindow.merge.sessions.in.local.partition true

# -----------------------------
# Event Log Settings
# -----------------------------
spark.eventLog.enabled             true
spark.eventLog.dir                 /mnt/c/wsl_mount_point/spark_logs/eventlogs
spark.eventLog.logBlockUpdates.enabled true
spark.eventLog.longForm.enabled true

# -----------------------------
# Spark UI Settings
# -----------------------------
spark.ui.showConsoleProgress true

# Misc
spark.checkpoint.compress true
mapreduce.fileoutputcommitter.algorithm.version 2

