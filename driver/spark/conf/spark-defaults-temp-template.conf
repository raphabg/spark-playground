# ============================================
# Spark Application Configuration
# ============================================

# -----------------------------
# Application Settings
# -----------------------------
spark.app.name                     Balogo_Raphael_Spark_Playground
# Options could be local[*], yarn, mesos, or spark://<host>:<port>.
spark.master                       spark://localhost:7077

# -----------------------------
# Driver Settings
# -----------------------------
spark.driver.memory                2g
spark.driver.extraJavaOptions      -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps  -Xloggc:/mnt/c/wsl_mount_point/spark_logs/driver_logs/driver.stdout.gc.log

# -----------------------------
# Executor Settings
# -----------------------------
spark.executor.instances           5
spark.executor.memory              2g
spark.executor.cores               1

# -----------------------------
# SQL Settings
# -----------------------------
spark.sql.shuffle.partitions       100


# -----------------------------
# Event Log Settings
# -----------------------------
# Enable Spark event logging for monitoring and replay via the Spark History Server.
spark.eventLog.enabled             true

# Directory where Spark event logs are stored. Must be accessible from the driver.
spark.eventLog.dir                 /mnt/c/wsl_mount_point/spark_logs/eventlogs

# ============================================
# Executor Log Rolling Settings
# ============================================
# Roll executor logs when the file size exceeds 100MB.
spark.executor.logs.rolling.strategy        time-size
spark.executor.logs.rolling.maxSize         100m
# Number of rolled log files to keep per executor.
spark.executor.logs.rolling.maxRetainedFiles  5
# Limit total size of all retained rolled log files (Spark 3.4+).
spark.executor.logs.rolling.maxRetainedFileSize  512m
# Enable compression of old rolled log files to save disk space.
spark.executor.logs.rolling.enableCompression   true


